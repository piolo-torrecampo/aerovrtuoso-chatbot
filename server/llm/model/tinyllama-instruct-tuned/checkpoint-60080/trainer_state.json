{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 60080,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.16644474034620507,
      "grad_norm": 0.18268252909183502,
      "learning_rate": 9.993165906006488e-05,
      "loss": 0.3342,
      "step": 1000
    },
    {
      "epoch": 0.33288948069241014,
      "grad_norm": 0.16139426827430725,
      "learning_rate": 9.972682305962232e-05,
      "loss": 0.0851,
      "step": 2000
    },
    {
      "epoch": 0.4993342210386152,
      "grad_norm": 0.12312309443950653,
      "learning_rate": 9.938605194606443e-05,
      "loss": 0.0782,
      "step": 3000
    },
    {
      "epoch": 0.6657789613848203,
      "grad_norm": 0.11281276494264603,
      "learning_rate": 9.891027726411939e-05,
      "loss": 0.0754,
      "step": 4000
    },
    {
      "epoch": 0.8322237017310253,
      "grad_norm": 0.0951174795627594,
      "learning_rate": 9.830079960934562e-05,
      "loss": 0.0736,
      "step": 5000
    },
    {
      "epoch": 0.9986684420772304,
      "grad_norm": 0.11608169227838516,
      "learning_rate": 9.7559285072775e-05,
      "loss": 0.0726,
      "step": 6000
    },
    {
      "epoch": 1.1651131824234353,
      "grad_norm": 0.10445793718099594,
      "learning_rate": 9.668776068642373e-05,
      "loss": 0.0717,
      "step": 7000
    },
    {
      "epoch": 1.3315579227696404,
      "grad_norm": 0.07455231994390488,
      "learning_rate": 9.568860888212137e-05,
      "loss": 0.0714,
      "step": 8000
    },
    {
      "epoch": 1.4980026631158454,
      "grad_norm": 0.07256966829299927,
      "learning_rate": 9.45645609788057e-05,
      "loss": 0.0708,
      "step": 9000
    },
    {
      "epoch": 1.6644474034620504,
      "grad_norm": 0.08324868977069855,
      "learning_rate": 9.331868971608648e-05,
      "loss": 0.0704,
      "step": 10000
    },
    {
      "epoch": 1.8308921438082557,
      "grad_norm": 0.06789619475603104,
      "learning_rate": 9.195440085448905e-05,
      "loss": 0.07,
      "step": 11000
    },
    {
      "epoch": 1.9973368841544608,
      "grad_norm": 0.07485402375459671,
      "learning_rate": 9.047695880898156e-05,
      "loss": 0.0702,
      "step": 12000
    },
    {
      "epoch": 2.1637816245006656,
      "grad_norm": 0.0857996940612793,
      "learning_rate": 8.888744520341842e-05,
      "loss": 0.0698,
      "step": 13000
    },
    {
      "epoch": 2.3302263648468706,
      "grad_norm": 0.058805909007787704,
      "learning_rate": 8.719162741558018e-05,
      "loss": 0.0695,
      "step": 14000
    },
    {
      "epoch": 2.4966711051930757,
      "grad_norm": 0.06041807681322098,
      "learning_rate": 8.539598785338424e-05,
      "loss": 0.0695,
      "step": 15000
    },
    {
      "epoch": 2.6631158455392807,
      "grad_norm": 0.08836642652750015,
      "learning_rate": 8.35018410906173e-05,
      "loss": 0.0694,
      "step": 16000
    },
    {
      "epoch": 2.8295605858854858,
      "grad_norm": 0.06221960484981537,
      "learning_rate": 8.151611243546278e-05,
      "loss": 0.0693,
      "step": 17000
    },
    {
      "epoch": 2.996005326231691,
      "grad_norm": 0.07411961257457733,
      "learning_rate": 7.944423015043058e-05,
      "loss": 0.0693,
      "step": 18000
    },
    {
      "epoch": 3.1624500665778963,
      "grad_norm": 0.05470822751522064,
      "learning_rate": 7.729404864685966e-05,
      "loss": 0.0688,
      "step": 19000
    },
    {
      "epoch": 3.3288948069241013,
      "grad_norm": 0.05919347330927849,
      "learning_rate": 7.50671420559402e-05,
      "loss": 0.069,
      "step": 20000
    },
    {
      "epoch": 3.4953395472703064,
      "grad_norm": 0.04581686109304428,
      "learning_rate": 7.277171098303712e-05,
      "loss": 0.0689,
      "step": 21000
    },
    {
      "epoch": 3.6617842876165114,
      "grad_norm": 0.05978642776608467,
      "learning_rate": 7.041403030483356e-05,
      "loss": 0.0688,
      "step": 22000
    },
    {
      "epoch": 3.8282290279627165,
      "grad_norm": 0.06564727425575256,
      "learning_rate": 6.800054506587412e-05,
      "loss": 0.0687,
      "step": 23000
    },
    {
      "epoch": 3.9946737683089215,
      "grad_norm": 0.061954692006111145,
      "learning_rate": 6.554033790085354e-05,
      "loss": 0.0689,
      "step": 24000
    },
    {
      "epoch": 4.161118508655126,
      "grad_norm": 0.06658320128917694,
      "learning_rate": 6.303520990834248e-05,
      "loss": 0.0685,
      "step": 25000
    },
    {
      "epoch": 4.327563249001331,
      "grad_norm": 0.048557352274656296,
      "learning_rate": 6.049444837593591e-05,
      "loss": 0.0684,
      "step": 26000
    },
    {
      "epoch": 4.494007989347536,
      "grad_norm": 0.055413514375686646,
      "learning_rate": 5.792758027187315e-05,
      "loss": 0.0686,
      "step": 27000
    },
    {
      "epoch": 4.660452729693741,
      "grad_norm": 0.051627017557621,
      "learning_rate": 5.533648478037056e-05,
      "loss": 0.0686,
      "step": 28000
    },
    {
      "epoch": 4.826897470039947,
      "grad_norm": 0.05975376442074776,
      "learning_rate": 5.273080127343434e-05,
      "loss": 0.0683,
      "step": 29000
    },
    {
      "epoch": 4.993342210386151,
      "grad_norm": 0.05427594482898712,
      "learning_rate": 5.0120267245933385e-05,
      "loss": 0.0683,
      "step": 30000
    },
    {
      "epoch": 5.159786950732357,
      "grad_norm": 0.056743450462818146,
      "learning_rate": 4.750679384956766e-05,
      "loss": 0.0683,
      "step": 31000
    },
    {
      "epoch": 5.326231691078562,
      "grad_norm": 0.06295103579759598,
      "learning_rate": 4.490013597527283e-05,
      "loss": 0.0681,
      "step": 32000
    },
    {
      "epoch": 5.492676431424767,
      "grad_norm": 0.06277918070554733,
      "learning_rate": 4.230741928101767e-05,
      "loss": 0.0683,
      "step": 33000
    },
    {
      "epoch": 5.659121171770972,
      "grad_norm": 0.05930761247873306,
      "learning_rate": 3.973829015316212e-05,
      "loss": 0.068,
      "step": 34000
    },
    {
      "epoch": 5.8255659121171774,
      "grad_norm": 0.054781921207904816,
      "learning_rate": 3.71971567583698e-05,
      "loss": 0.0679,
      "step": 35000
    },
    {
      "epoch": 5.9920106524633825,
      "grad_norm": 0.05454769358038902,
      "learning_rate": 3.4688462830633144e-05,
      "loss": 0.068,
      "step": 36000
    },
    {
      "epoch": 6.1584553928095875,
      "grad_norm": 0.07200092077255249,
      "learning_rate": 3.222162509657675e-05,
      "loss": 0.0679,
      "step": 37000
    },
    {
      "epoch": 6.324900133155793,
      "grad_norm": 0.04898364469408989,
      "learning_rate": 2.980338699657711e-05,
      "loss": 0.0678,
      "step": 38000
    },
    {
      "epoch": 6.491344873501998,
      "grad_norm": 0.05363789573311806,
      "learning_rate": 2.7442692404145886e-05,
      "loss": 0.068,
      "step": 39000
    },
    {
      "epoch": 6.657789613848203,
      "grad_norm": 0.05909481272101402,
      "learning_rate": 2.5141269565471702e-05,
      "loss": 0.0676,
      "step": 40000
    },
    {
      "epoch": 6.824234354194408,
      "grad_norm": 0.050475917756557465,
      "learning_rate": 2.2909998963185342e-05,
      "loss": 0.0679,
      "step": 41000
    },
    {
      "epoch": 6.990679094540613,
      "grad_norm": 0.06140851601958275,
      "learning_rate": 2.075263460547502e-05,
      "loss": 0.0677,
      "step": 42000
    },
    {
      "epoch": 7.157123834886818,
      "grad_norm": 0.05378793552517891,
      "learning_rate": 1.867302439511289e-05,
      "loss": 0.0675,
      "step": 43000
    },
    {
      "epoch": 7.323568575233023,
      "grad_norm": 0.05549611151218414,
      "learning_rate": 1.6679050783077295e-05,
      "loss": 0.0675,
      "step": 44000
    },
    {
      "epoch": 7.490013315579228,
      "grad_norm": 0.051870375871658325,
      "learning_rate": 1.4776164570602302e-05,
      "loss": 0.0676,
      "step": 45000
    },
    {
      "epoch": 7.656458055925433,
      "grad_norm": 0.06430518627166748,
      "learning_rate": 1.2969567558981948e-05,
      "loss": 0.0676,
      "step": 46000
    },
    {
      "epoch": 7.822902796271638,
      "grad_norm": 0.05222836136817932,
      "learning_rate": 1.126419832973053e-05,
      "loss": 0.0674,
      "step": 47000
    },
    {
      "epoch": 7.989347536617843,
      "grad_norm": 0.05489456653594971,
      "learning_rate": 9.666263851998053e-06,
      "loss": 0.0677,
      "step": 48000
    },
    {
      "epoch": 8.155792276964048,
      "grad_norm": 0.07773831486701965,
      "learning_rate": 8.176933961213334e-06,
      "loss": 0.0673,
      "step": 49000
    },
    {
      "epoch": 8.322237017310252,
      "grad_norm": 0.056981511414051056,
      "learning_rate": 6.803249791989214e-06,
      "loss": 0.0674,
      "step": 50000
    },
    {
      "epoch": 8.488681757656458,
      "grad_norm": 0.07647354155778885,
      "learning_rate": 5.546217007844134e-06,
      "loss": 0.0673,
      "step": 51000
    },
    {
      "epoch": 8.655126498002662,
      "grad_norm": 0.05998504161834717,
      "learning_rate": 4.411778507729297e-06,
      "loss": 0.0674,
      "step": 52000
    },
    {
      "epoch": 8.821571238348868,
      "grad_norm": 0.06501328200101852,
      "learning_rate": 3.4007648052657158e-06,
      "loss": 0.0674,
      "step": 53000
    },
    {
      "epoch": 8.988015978695072,
      "grad_norm": 0.06448105722665787,
      "learning_rate": 2.5171365241408065e-06,
      "loss": 0.0671,
      "step": 54000
    },
    {
      "epoch": 9.154460719041278,
      "grad_norm": 0.05676223337650299,
      "learning_rate": 1.7633091838459626e-06,
      "loss": 0.0673,
      "step": 55000
    },
    {
      "epoch": 9.320905459387482,
      "grad_norm": 0.05785553157329559,
      "learning_rate": 1.1418989797990054e-06,
      "loss": 0.0674,
      "step": 56000
    },
    {
      "epoch": 9.487350199733688,
      "grad_norm": 0.05811353400349617,
      "learning_rate": 6.533608415872583e-07,
      "loss": 0.067,
      "step": 57000
    },
    {
      "epoch": 9.653794940079894,
      "grad_norm": 0.05908983573317528,
      "learning_rate": 2.997185314845441e-07,
      "loss": 0.0673,
      "step": 58000
    },
    {
      "epoch": 9.820239680426099,
      "grad_norm": 0.06779005378484726,
      "learning_rate": 8.193877940579908e-08,
      "loss": 0.0673,
      "step": 59000
    },
    {
      "epoch": 9.986684420772303,
      "grad_norm": 0.07139167934656143,
      "learning_rate": 6.299723091407472e-10,
      "loss": 0.0673,
      "step": 60000
    }
  ],
  "logging_steps": 1000,
  "max_steps": 60080,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.814425367173284e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
